
# ğŸ§© TaskFlow API

A Django RESTful API for managing personal or team tasks â€” featuring PostgreSQL, RabbitMQ, Docker support, and developer/production-ready configurations.

---

## ğŸš€ Features

- âœ… Django 5 + Django REST Framework
- âœ… PostgreSQL database (via Docker)
- âœ… RabbitMQ for background tasks (Celery integrated)
- âœ… Asynchronous task logging using Celery
- âœ… Environment config with `.env` and `python-decouple`
- âœ… Swagger UI for API documentation
- âœ… Containerized with Docker
- âœ… CLI scripts for development and production modes

---

## ğŸ“ Project Structure

```
taskflow-api/
â”œâ”€â”€ taskflow_api/           # Django project (includes celery.py)
â”œâ”€â”€ tasks/                  # App: task models, views, serializers, signals, celery tasks
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ Dockerfile              # Production image for gunicorn
â”œâ”€â”€ docker-compose.yml      # DB and RabbitMQ container setup
â”œâ”€â”€ .env                    # Environment configuration
â”œâ”€â”€ logs/                   # Directory for activity logs (auto-created)
â”œâ”€â”€ run_server.sh           # Run production server (Gunicorn)
â””â”€â”€ start-dev-services.sh   # Run DB + RabbitMQ for development
```

---

## âš™ï¸ Prerequisites

- Python 3.12+
- Docker & Docker Compose
- Virtualenv (optional but recommended)

---

## ğŸ“¦ Setup Instructions

### ğŸ”§ 1. Install Python Dependencies
```bash
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt
```

### ğŸ”§ 2. Configure Environment
Edit `.env` (already provided):
```dotenv
DEBUG=True
SECRET_KEY=your-secret-key
DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1,[::1]

POSTGRES_DB=taskflow
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

CELERY_BROKER_URL=amqp://guest:guest@localhost:5672//
```

---

## ğŸ§ª Development Mode

Use this when you want to run Django locally (`runserver`) and containers only for DB/RabbitMQ.

### â–¶ï¸ Start Docker Services:
```bash
./start-dev-services.sh
```

> This will:
> - Start PostgreSQL and RabbitMQ containers
> - Stop and remove any running web container
> - Run DB migrations automatically

### â–¶ï¸ Then Run Django:
```bash
python3 manage.py runserver
```

### â–¶ï¸ Run Celery Worker:
```bash
celery -A taskflow_api worker --loglevel=info
```

Open:
- Swagger docs: http://localhost:8000/docs/
- API root: http://localhost:8000/api/tasks/

---

## ğŸ§© Celery Logging Task

When a task is created through the API, a Celery worker will automatically:

- Run `log_task_action` in the background using `celery -A taskflow_api worker --loglevel=info`
- Write an entry like this to `logs/task_activity.log`:

```
[2025-09-14 19:45:00] Task #12 ('Example Task') was created
```

---

## ğŸ­ Production Mode (Dockerized Web)

### â–¶ï¸ Build & Run All Services:
```bash
./run_server.sh
```

> This uses Docker to run:
> - Django (with Gunicorn)
> - PostgreSQL
> - RabbitMQ

You can also run manually:
```bash
docker compose up --build
```

---

## ğŸ—ƒï¸ Tech Stack

- **Backend**: Django 5, DRF
- **Database**: PostgreSQL (Docker)
- **Broker**: RabbitMQ (Docker)
- **Background Jobs**: Celery (activity logging)
- **Containerization**: Docker, Docker Compose
- **CI-ready**: Gunicorn + environment-based config

---

## ğŸ“œ License

MIT Â© Omid Hashemzadeh